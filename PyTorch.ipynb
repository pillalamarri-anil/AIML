{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkf2PwBrQGSR+IassCoUui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pillalamarri-anil/AIML/blob/main/PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g8RuUI-YJRIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6eb18931-e81a-4b8b-e899-fdeb098d0d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[4.3572e-37, 4.3222e-41, 4.3571e-37, 4.3222e-41],\n",
            "         [4.3573e-37, 4.3222e-41, 4.3573e-37, 4.3222e-41]],\n",
            "\n",
            "        [[4.3573e-37, 4.3222e-41, 4.3574e-37, 4.3222e-41],\n",
            "         [4.3574e-37, 4.3222e-41, 4.3574e-37, 4.3222e-41]]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.empty(2, 2, 4) # scaler\n",
        "\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "y = torch.zeros(2, 2, 4) # scaler\n",
        "\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M4-aNx0rQkKn",
        "outputId": "e28dd125-b1fd-48a9-e060-c270669e5ca8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.ones(2, 2, 4) # scaler\n",
        "\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Sld_RELJQ80x",
        "outputId": "518caffa-300d-4331-d0fa-4d52673b3e54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8skb6KoRIgg",
        "outputId": "21cbed97-0d42-4803-a0d6-2267a6a25980"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBeC_sFpReWa",
        "outputId": "c83bcb72-ca52-4f95-8ada-47888a967b1f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0,2,3], requires_grad=True)\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTtW85iDRnd_",
        "outputId": "a8aae1b2-d3cb-4695-ea3a-284f6fe3bdee"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(3,2)\n",
        "print(x)\n",
        "\n",
        "y = torch.ones(3,2)\n",
        "print(y)\n",
        "\n",
        "z = x * y\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSYYbO48Sc4P",
        "outputId": "20254402-d0fa-42eb-d450-c3008d0a4847"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0, 0].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-zCln7iTLwF",
        "outputId": "eaaa6360-759e-4226-d9dd-e093f5524fd0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(4,4)\n",
        "print(x)\n",
        "y = x.view(16)\n",
        "print(y)\n",
        "\n",
        "z = x.view(-1, 8)\n",
        "print(z)\n",
        "\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePkBZMMhUIju",
        "outputId": "57345659-ab51-4533-954d-a063a4acaf26"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.9069,  0.4168, -0.6493, -0.2141],\n",
            "        [ 0.5068, -0.7835,  0.1475,  1.0205],\n",
            "        [-0.4900,  0.9380,  0.1221, -0.1911],\n",
            "        [-0.4721,  0.1798, -1.2380, -0.1608]])\n",
            "tensor([ 0.9069,  0.4168, -0.6493, -0.2141,  0.5068, -0.7835,  0.1475,  1.0205,\n",
            "        -0.4900,  0.9380,  0.1221, -0.1911, -0.4721,  0.1798, -1.2380, -0.1608])\n",
            "tensor([[ 0.9069,  0.4168, -0.6493, -0.2141,  0.5068, -0.7835,  0.1475,  1.0205],\n",
            "        [-0.4900,  0.9380,  0.1221, -0.1911, -0.4721,  0.1798, -1.2380, -0.1608]])\n",
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Dfk0-s2qSclv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5, 2)\n",
        "print(a)\n",
        "\n",
        "b = a.numpy()\n",
        "print(type(b))\n",
        "\n",
        "a.add_(1)\n",
        "\n",
        "print(a)\n",
        "\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iRs5ZGSYU8bn",
        "outputId": "4c285f35-510d-4482-a3e5-519c79fea338"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "[[2. 2.]\n",
            " [2. 2.]\n",
            " [2. 2.]\n",
            " [2. 2.]\n",
            " [2. 2.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "a = numpy.ones(5)\n",
        "print(a)\n",
        "\n",
        "b = torch.from_numpy(a)\n",
        "c = torch.tensor(a)\n",
        "print(b)\n",
        "\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viy7130jVuBP",
        "outputId": "8244592f-bcd5-4fc0-d2ac-76ad0a7db1e8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "x = x.to('cuda:0')\n",
        "\n",
        "x = torch.rand(10, 10, 10, device=device)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VqE7KVpsWoUU",
        "outputId": "22eb91e0-02f2-448e-cac4-672a924fb6e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "tensor([[[0.0233, 0.0194, 0.0601, 0.5863, 0.6989, 0.8070, 0.1228, 0.2833,\n",
            "          0.8129, 0.2329],\n",
            "         [0.5616, 0.1250, 0.0420, 0.4779, 0.9522, 0.6028, 0.3767, 0.1034,\n",
            "          0.6120, 0.4083],\n",
            "         [0.8505, 0.6319, 0.5005, 0.5553, 0.7490, 0.6133, 0.4001, 0.3642,\n",
            "          0.2180, 0.5121],\n",
            "         [0.7767, 0.8644, 0.2640, 0.0478, 0.6926, 0.6971, 0.4679, 0.2945,\n",
            "          0.1108, 0.2736],\n",
            "         [0.3773, 0.4623, 0.2867, 0.9553, 0.1291, 0.5936, 0.7700, 0.6592,\n",
            "          0.1181, 0.7646],\n",
            "         [0.5415, 0.6072, 0.9541, 0.1699, 0.6680, 0.6408, 0.4951, 0.1246,\n",
            "          0.7215, 0.9077],\n",
            "         [0.2005, 0.2683, 0.5221, 0.4655, 0.1176, 0.5366, 0.5571, 0.6367,\n",
            "          0.1720, 0.2935],\n",
            "         [0.0427, 0.4511, 0.3278, 0.1856, 0.0795, 0.2174, 0.1256, 0.9700,\n",
            "          0.5112, 0.0198],\n",
            "         [0.6914, 0.5432, 0.5994, 0.3571, 0.5593, 0.3287, 0.2525, 0.5267,\n",
            "          0.2854, 0.1618],\n",
            "         [0.2268, 0.8417, 0.4817, 0.6763, 0.5418, 0.9712, 0.1023, 0.8084,\n",
            "          0.4896, 0.3229]],\n",
            "\n",
            "        [[0.7126, 0.3878, 0.5201, 0.4474, 0.5083, 0.7175, 0.8354, 0.3107,\n",
            "          0.6028, 0.1370],\n",
            "         [0.0040, 0.8190, 0.7096, 0.8704, 0.9236, 0.9817, 0.4350, 0.0215,\n",
            "          0.8878, 0.8144],\n",
            "         [0.9926, 0.4459, 0.0565, 0.1606, 0.3336, 0.1966, 0.0409, 0.1822,\n",
            "          0.4014, 0.8556],\n",
            "         [0.9338, 0.2158, 0.7247, 0.6704, 0.0555, 0.8174, 0.8524, 0.4985,\n",
            "          0.0896, 0.1233],\n",
            "         [0.0841, 0.1587, 0.4480, 0.5629, 0.3449, 0.0274, 0.8509, 0.4382,\n",
            "          0.8158, 0.9165],\n",
            "         [0.5712, 0.5525, 0.9436, 0.1447, 0.9659, 0.8257, 0.4422, 0.6823,\n",
            "          0.1137, 0.6227],\n",
            "         [0.1021, 0.7150, 0.4327, 0.6319, 0.7232, 0.6427, 0.1179, 0.2035,\n",
            "          0.6561, 0.0293],\n",
            "         [0.0780, 0.4128, 0.4877, 0.8449, 0.9715, 0.8280, 0.1056, 0.7125,\n",
            "          0.6812, 0.8739],\n",
            "         [0.1650, 0.0678, 0.7176, 0.0431, 0.5330, 0.1459, 0.7848, 0.6028,\n",
            "          0.1503, 0.2322],\n",
            "         [0.1738, 0.1684, 0.4104, 0.2674, 0.4574, 0.3146, 0.3579, 0.9443,\n",
            "          0.1963, 0.3249]],\n",
            "\n",
            "        [[0.2885, 0.9365, 0.2334, 0.6077, 0.8574, 0.6645, 0.9310, 0.8449,\n",
            "          0.6871, 0.2671],\n",
            "         [0.8643, 0.5127, 0.4854, 0.2406, 0.5956, 0.1593, 0.2157, 0.3227,\n",
            "          0.1667, 0.8198],\n",
            "         [0.9543, 0.2746, 0.1944, 0.9193, 0.9685, 0.4210, 0.5461, 0.2942,\n",
            "          0.2658, 0.5800],\n",
            "         [0.4991, 0.4504, 0.9719, 0.7063, 0.7094, 0.9459, 0.3573, 0.0596,\n",
            "          0.5400, 0.3017],\n",
            "         [0.8690, 0.3141, 0.8212, 0.5108, 0.7788, 0.9347, 0.0511, 0.3547,\n",
            "          0.2868, 0.1567],\n",
            "         [0.0138, 0.9532, 0.8717, 0.8134, 0.8604, 0.1554, 0.1127, 0.5173,\n",
            "          0.8498, 0.2358],\n",
            "         [0.2417, 0.1364, 0.2551, 0.1627, 0.8156, 0.0413, 0.7020, 0.0879,\n",
            "          0.1994, 0.6061],\n",
            "         [0.9411, 0.8694, 0.7876, 0.5725, 0.2654, 0.0483, 0.7709, 0.9400,\n",
            "          0.2863, 0.2135],\n",
            "         [0.3597, 0.0025, 0.6660, 0.8220, 0.5017, 0.5989, 0.7568, 0.5480,\n",
            "          0.1211, 0.6741],\n",
            "         [0.8618, 0.4460, 0.2467, 0.0143, 0.0911, 0.3250, 0.7161, 0.9100,\n",
            "          0.7013, 0.4551]],\n",
            "\n",
            "        [[0.0630, 0.6590, 0.9202, 0.5830, 0.0107, 0.8694, 0.8232, 0.6794,\n",
            "          0.6695, 0.1823],\n",
            "         [0.6722, 0.9170, 0.0879, 0.6314, 0.6638, 0.3380, 0.9763, 0.8319,\n",
            "          0.3308, 0.0840],\n",
            "         [0.4170, 0.5627, 0.7930, 0.9151, 0.6704, 0.6451, 0.8776, 0.3049,\n",
            "          0.9809, 0.2905],\n",
            "         [0.9719, 0.9804, 0.4801, 0.5662, 0.7862, 0.5605, 0.5358, 0.9710,\n",
            "          0.5390, 0.3822],\n",
            "         [0.0309, 0.0085, 0.5035, 0.1358, 0.7859, 0.5447, 0.3234, 0.5257,\n",
            "          0.6163, 0.1047],\n",
            "         [0.9370, 0.5144, 0.6482, 0.1416, 0.0719, 0.4425, 0.9698, 0.5964,\n",
            "          0.0234, 0.1731],\n",
            "         [0.4040, 0.5774, 0.0891, 0.1860, 0.7458, 0.4887, 0.6941, 0.6414,\n",
            "          0.8499, 0.5482],\n",
            "         [0.1862, 0.1045, 0.3604, 0.6491, 0.6648, 0.8963, 0.3085, 0.9747,\n",
            "          0.8167, 0.3652],\n",
            "         [0.1609, 0.8826, 0.4461, 0.3687, 0.2352, 0.3920, 0.1562, 0.0424,\n",
            "          0.2219, 0.2324],\n",
            "         [0.3441, 0.3527, 0.1988, 0.1304, 0.2266, 0.9529, 0.7435, 0.2392,\n",
            "          0.8360, 0.8746]],\n",
            "\n",
            "        [[0.4242, 0.4306, 0.8151, 0.0916, 0.3604, 0.7378, 0.6985, 0.3887,\n",
            "          0.6377, 0.6445],\n",
            "         [0.3669, 0.9553, 0.1747, 0.1709, 0.4800, 0.1591, 0.9107, 0.3598,\n",
            "          0.4183, 0.8573],\n",
            "         [0.1207, 0.3423, 0.7289, 0.7858, 0.7790, 0.5029, 0.8891, 0.2872,\n",
            "          0.0759, 0.3375],\n",
            "         [0.1843, 0.2315, 0.4362, 0.3198, 0.8397, 0.7262, 0.5073, 0.8878,\n",
            "          0.0901, 0.6128],\n",
            "         [0.1139, 0.0013, 0.8016, 0.0480, 0.7034, 0.7583, 0.1397, 0.6638,\n",
            "          0.1149, 0.6640],\n",
            "         [0.7233, 0.9115, 0.5900, 0.5308, 0.5869, 0.5296, 0.4629, 0.8241,\n",
            "          0.7411, 0.8873],\n",
            "         [0.5957, 0.4506, 0.3371, 0.4677, 0.9445, 0.3368, 0.0992, 0.9643,\n",
            "          0.3580, 0.0477],\n",
            "         [0.0807, 0.6843, 0.1746, 0.5608, 0.4110, 0.9164, 0.7839, 0.4094,\n",
            "          0.0594, 0.7240],\n",
            "         [0.3406, 0.9092, 0.5427, 0.7157, 0.5137, 0.3572, 0.7234, 0.7427,\n",
            "          0.5846, 0.1938],\n",
            "         [0.2644, 0.4285, 0.6180, 0.0487, 0.7652, 0.0838, 0.7389, 0.3893,\n",
            "          0.3375, 0.4343]],\n",
            "\n",
            "        [[0.0168, 0.3879, 0.9079, 0.2211, 0.8324, 0.9961, 0.6273, 0.4767,\n",
            "          0.9545, 0.8672],\n",
            "         [0.3701, 0.5969, 0.9335, 0.6725, 0.2457, 0.7416, 0.2861, 0.2598,\n",
            "          0.7433, 0.0480],\n",
            "         [0.8924, 0.0048, 0.6717, 0.9476, 0.3849, 0.6851, 0.5900, 0.7493,\n",
            "          0.4618, 0.3608],\n",
            "         [0.7225, 0.4661, 0.8212, 0.3583, 0.7419, 0.9319, 0.4396, 0.1116,\n",
            "          0.6754, 0.9344],\n",
            "         [0.8347, 0.5829, 0.1920, 0.4319, 0.0458, 0.2039, 0.9635, 0.5104,\n",
            "          0.5395, 0.3858],\n",
            "         [0.3646, 0.3733, 0.5613, 0.2826, 0.4024, 0.3706, 0.0168, 0.9240,\n",
            "          0.1981, 0.6705],\n",
            "         [0.0975, 0.6726, 0.5433, 0.2247, 0.3180, 0.7328, 0.6356, 0.9111,\n",
            "          0.6789, 0.6341],\n",
            "         [0.3296, 0.1545, 0.1894, 0.4074, 0.7227, 0.5633, 0.8574, 0.5248,\n",
            "          0.3992, 0.7333],\n",
            "         [0.3592, 0.8423, 0.9218, 0.2097, 0.2227, 0.4918, 0.7639, 0.8809,\n",
            "          0.9993, 0.2444],\n",
            "         [0.4800, 0.9649, 0.6104, 0.0649, 0.6410, 0.0238, 0.6172, 0.3214,\n",
            "          0.3971, 0.4743]],\n",
            "\n",
            "        [[0.3240, 0.3366, 0.5479, 0.6868, 0.2917, 0.0279, 0.3400, 0.9818,\n",
            "          0.8526, 0.6275],\n",
            "         [0.4679, 0.7236, 0.9719, 0.1529, 0.0803, 0.2433, 0.4176, 0.9097,\n",
            "          0.5511, 0.5613],\n",
            "         [0.8537, 0.2318, 0.9935, 0.5630, 0.6740, 0.0339, 0.2044, 0.4693,\n",
            "          0.4962, 0.2234],\n",
            "         [0.2195, 0.2629, 0.6968, 0.0168, 0.6775, 0.6203, 0.1042, 0.4742,\n",
            "          0.8578, 0.2950],\n",
            "         [0.2632, 0.0423, 0.0021, 0.0145, 0.6797, 0.2881, 0.2549, 0.0788,\n",
            "          0.3093, 0.5966],\n",
            "         [0.9033, 0.9509, 0.5316, 0.5534, 0.4516, 0.1962, 0.7119, 0.0123,\n",
            "          0.4617, 0.0945],\n",
            "         [0.2398, 0.3846, 0.7184, 0.8242, 0.2919, 0.4254, 0.5509, 0.3287,\n",
            "          0.2156, 0.2354],\n",
            "         [0.9106, 0.1406, 0.9845, 0.1698, 0.8588, 0.1977, 0.7524, 0.5197,\n",
            "          0.2868, 0.4017],\n",
            "         [0.4052, 0.7116, 0.8340, 0.7471, 0.3908, 0.7213, 0.1271, 0.0397,\n",
            "          0.8236, 0.2462],\n",
            "         [0.2602, 0.3263, 0.5315, 0.2098, 0.0215, 0.2245, 0.9692, 0.8296,\n",
            "          0.1375, 0.9024]],\n",
            "\n",
            "        [[0.7115, 0.1717, 0.9378, 0.0397, 0.2001, 0.9617, 0.5972, 0.7208,\n",
            "          0.8877, 0.4010],\n",
            "         [0.9622, 0.6128, 0.2415, 0.8479, 0.6131, 0.4056, 0.5428, 0.7126,\n",
            "          0.0548, 0.7116],\n",
            "         [0.0321, 0.5286, 0.2221, 0.2337, 0.1962, 0.0549, 0.7332, 0.4714,\n",
            "          0.5462, 0.6563],\n",
            "         [0.1827, 0.3223, 0.8070, 0.1005, 0.6440, 0.1165, 0.6332, 0.3117,\n",
            "          0.9396, 0.1247],\n",
            "         [0.2656, 0.8438, 0.6616, 0.8424, 0.0499, 0.7044, 0.6612, 0.5965,\n",
            "          0.1356, 0.9455],\n",
            "         [0.6856, 0.1314, 0.3939, 0.2161, 0.4430, 0.8620, 0.5402, 0.7324,\n",
            "          0.3277, 0.5311],\n",
            "         [0.0988, 0.3642, 0.9415, 0.6351, 0.3152, 0.4861, 0.0825, 0.4643,\n",
            "          0.7410, 0.1272],\n",
            "         [0.8289, 0.1871, 0.5987, 0.6127, 0.1329, 0.3238, 0.7030, 0.9575,\n",
            "          0.8861, 0.8362],\n",
            "         [0.6361, 0.7621, 0.4587, 0.7772, 0.6083, 0.3003, 0.3665, 0.9997,\n",
            "          0.7261, 0.0601],\n",
            "         [0.1554, 0.0127, 0.3470, 0.1514, 0.5477, 0.2768, 0.6022, 0.0395,\n",
            "          0.1408, 0.9933]],\n",
            "\n",
            "        [[0.4892, 0.6022, 0.7483, 0.2747, 0.4636, 0.4332, 0.9706, 0.7684,\n",
            "          0.3149, 0.0974],\n",
            "         [0.7154, 0.7721, 0.6055, 0.7964, 0.4762, 0.7724, 0.9069, 0.3461,\n",
            "          0.4557, 0.4888],\n",
            "         [0.1838, 0.8030, 0.5659, 0.1894, 0.8288, 0.8640, 0.9268, 0.6175,\n",
            "          0.5148, 0.0630],\n",
            "         [0.6417, 0.9573, 0.2967, 0.5219, 0.8730, 0.7046, 0.3893, 0.1925,\n",
            "          0.2760, 0.0834],\n",
            "         [0.9340, 0.9987, 0.5507, 0.7457, 0.5218, 0.0332, 0.3493, 0.5743,\n",
            "          0.3401, 0.8940],\n",
            "         [0.5456, 0.9683, 0.9993, 0.7565, 0.6434, 0.4131, 0.4968, 0.0742,\n",
            "          0.3980, 0.2926],\n",
            "         [0.5021, 0.0886, 0.9922, 0.9693, 0.8472, 0.4265, 0.2834, 0.1286,\n",
            "          0.0138, 0.1821],\n",
            "         [0.8860, 0.4105, 0.3533, 0.2699, 0.8777, 0.9759, 0.6804, 0.1389,\n",
            "          0.5875, 0.0611],\n",
            "         [0.8024, 0.5644, 0.2952, 0.4518, 0.6712, 0.6869, 0.2017, 0.0741,\n",
            "          0.0501, 0.1506],\n",
            "         [0.2278, 0.8804, 0.4668, 0.5883, 0.8161, 0.3679, 0.2643, 0.3030,\n",
            "          0.4909, 0.6703]],\n",
            "\n",
            "        [[0.0886, 0.9185, 0.4459, 0.9754, 0.5176, 0.1614, 0.5162, 0.9740,\n",
            "          0.0843, 0.8092],\n",
            "         [0.1590, 0.7486, 0.5963, 0.0597, 0.3570, 0.1093, 0.3314, 0.9220,\n",
            "          0.1098, 0.6441],\n",
            "         [0.5599, 0.0456, 0.1783, 0.0283, 0.0407, 0.2964, 0.6902, 0.2970,\n",
            "          0.8100, 0.9387],\n",
            "         [0.6260, 0.3489, 0.8498, 0.3110, 0.7630, 0.6451, 0.0514, 0.8412,\n",
            "          0.0231, 0.5862],\n",
            "         [0.9586, 0.4238, 0.6319, 0.4961, 0.2091, 0.8573, 0.1235, 0.3424,\n",
            "          0.3507, 0.0535],\n",
            "         [0.4851, 0.6615, 0.5910, 0.4913, 0.2422, 0.4634, 0.3820, 0.2526,\n",
            "          0.6167, 0.3092],\n",
            "         [0.6362, 0.6344, 0.3543, 0.4957, 0.6515, 0.4671, 0.4593, 0.3091,\n",
            "          0.3037, 0.8409],\n",
            "         [0.5652, 0.2572, 0.1472, 0.5675, 0.0232, 0.9161, 0.8262, 0.7191,\n",
            "          0.0922, 0.0558],\n",
            "         [0.7931, 0.9417, 0.1596, 0.8988, 0.9634, 0.1486, 0.8309, 0.8928,\n",
            "          0.4973, 0.4448],\n",
            "         [0.0315, 0.6062, 0.9907, 0.4749, 0.5941, 0.6551, 0.4464, 0.5788,\n",
            "          0.5670, 0.5729]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x + 2\n",
        "print(y)\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_JJgbSk3_FZ",
        "outputId": "4d43d24d-8bef-40f2-e9e6-250648b40ff0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.4196,  0.5953, -0.5585], requires_grad=True)\n",
            "tensor([2.4196, 2.5953, 1.4415], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x787c03707eb0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y * y\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXtBmLps7MEi",
        "outputId": "8f589a86-8b0e-42e5-f669-735c21dcebdf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.8543, 6.7355, 2.0780], grad_fn=<MulBackward0>)\n",
            "tensor(4.8893, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)\n",
        "z.backward()\n",
        "print(x.grad)  # dz/dx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvragota7mA3",
        "outputId": "12dae1c0-a8ba-4d41-ae69-6071e25d439b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([1.6130, 1.7302, 0.9610])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a = torch.randn(2,2)\n",
        "b = (a * 3) / (a - 1)\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)\n",
        "\n",
        "a.requires_grad_(True)\n",
        "b = (a * 3) / (a - 1)\n",
        "print(b.grad_fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP1Wd4xNIJDd",
        "outputId": "033be483-9013-45f6-e65f-75519af7e4f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "None\n",
            "<DivBackward0 object at 0x7ed1284f0f70>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2,2, requires_grad=True)\n",
        "with torch.no_grad():\n",
        "    b = a ** 3\n",
        "    print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUfcujE-JAA1",
        "outputId": "eb5e4e67-6560-4b38-cf7f-7ae403334240"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1,2,3,4,5,6,7,8], dtype=torch.float32)\n",
        "y = torch.tensor([2,4,6,8,10,12,14,16], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y) ** 2).mean()\n",
        "\n",
        "x_test = 5.0\n",
        "\n",
        "print(f'Prediction before training: f({x_test}) = {forward(x_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKvk_pMWKTsp",
        "outputId": "9aeddf8e-08ee-48b8-be49-ee35d2dfd3f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5.0) = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    y_pred = forward(x)\n",
        "\n",
        "    l = loss(y, y_pred)\n",
        "\n",
        "    l.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if(epoch % 10 == 0):\n",
        "        print(f'epoch {epoch + 1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "\n",
        "print(f'Prediction after training: f({x_test}) = {forward(x_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koOYplOoLPuf",
        "outputId": "72e565a7-a0cc-45b0-adf6-1b3762b8570a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w = 1.020, loss = 102.00000000\n",
            "epoch 11: w = 1.999, loss = 0.00006494\n",
            "epoch 21: w = 2.000, loss = 0.00000000\n",
            "epoch 31: w = 2.000, loss = 0.00000000\n",
            "epoch 41: w = 2.000, loss = 0.00000000\n",
            "epoch 51: w = 2.000, loss = 0.00000000\n",
            "epoch 61: w = 2.000, loss = 0.00000000\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5.0) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prompt_toolkit import output\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "x = torch.tensor([[1],[2],[3],[4],[5],[6],[7],[8]], dtype=torch.float32)\n",
        "y = torch.tensor([[2],[4],[6],[8],[10],[12],[14],[16]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = x.shape\n",
        "print(n_samples, n_features)\n",
        "\n",
        "x_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "input_dim, output_dim = n_features, n_features\n",
        "\n",
        "model = LinearRegression(input_dim, output_dim)\n",
        "\n",
        "print(f'Prediction before training: f({x_test.item()}) = {model(x_test).item():.3f}')\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_epochs = 200\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    y_pred = model(x)\n",
        "\n",
        "    l = loss(y, y_pred)\n",
        "\n",
        "    l.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    if(epoch+1) % 10 == 0:\n",
        "            w, b = model.parameters()\n",
        "            print(f'epoch {epoch + 1}: w = {w[0][0].item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training: f({x_test.item()}) = {model(x_test).item():.3f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjXVIJuMMsig",
        "outputId": "5687165a-af72-464d-c58d-0a35c86e769e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 1\n",
            "Prediction before training: f(5.0) = -1.163\n",
            "epoch 10: w = 1.904, loss = 0.05908001\n",
            "epoch 20: w = 1.909, loss = 0.05436580\n",
            "epoch 30: w = 1.913, loss = 0.05018559\n",
            "epoch 40: w = 1.916, loss = 0.04632682\n",
            "epoch 50: w = 1.919, loss = 0.04276472\n",
            "epoch 60: w = 1.922, loss = 0.03947660\n",
            "epoch 70: w = 1.925, loss = 0.03644126\n",
            "epoch 80: w = 1.928, loss = 0.03363927\n",
            "epoch 90: w = 1.931, loss = 0.03105275\n",
            "epoch 100: w = 1.934, loss = 0.02866513\n",
            "epoch 110: w = 1.936, loss = 0.02646111\n",
            "epoch 120: w = 1.939, loss = 0.02442653\n",
            "epoch 130: w = 1.941, loss = 0.02254838\n",
            "epoch 140: w = 1.944, loss = 0.02081459\n",
            "epoch 150: w = 1.946, loss = 0.01921422\n",
            "epoch 160: w = 1.948, loss = 0.01773685\n",
            "epoch 170: w = 1.950, loss = 0.01637304\n",
            "epoch 180: w = 1.952, loss = 0.01511411\n",
            "epoch 190: w = 1.954, loss = 0.01395202\n",
            "epoch 200: w = 1.956, loss = 0.01287923\n",
            "Prediction after training: f(5.0) = 10.028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transformers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#hyper parameters\n",
        "input_size = 784 #28*28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "#MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transformers.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transformers.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "collapsed": true,
        "id": "Pd5-Pc1xTswX",
        "outputId": "44b18ac4-5cc2-4bfc-f34b-62dfc99e2b15"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAGgCAYAAABCAKXYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOVRJREFUeJzt3Xt0VOW9//FvQpMBIZkQIAn5wUDECyiKGgIEEFGzjKgoiLcjp+JlgeCEilitKIql1qxFW6UiyGmPEi/lUlRQ0XK04VY0YJOKngBGsWjigoxQzUy4JZA8vz+6nMOzIZOZzG3vPe/XWnut+czsmfky+ZIne/bez05SSikBAAC2lBzvAgAAQPQw0AMAYGMM9AAA2BgDPQAANsZADwCAjTHQAwBgYwz0AADYGAM9AAA2xkAPAICNMdADAGBjURvoFy9eLP3795fOnTvL8OHD5eOPP47WWwERRe/CquhdnE5SNOa6X7Vqldxxxx2ydOlSGT58uCxcuFBWr14tNTU1kpWVFfC5ra2tsm/fPklLS5OkpKRIl4YoUEpJY2Oj5ObmSnKytb8koncTC737b/Su9YTUuyoKhg0bptxutz+3tLSo3NxcVVpa2u5z6+rqlIiwWHCpq6uLRjvFFL2bmAu9S+9adQmmdyP+J2xzc7NUVVVJUVGR/77k5GQpKiqSioqKU9ZvamoSn8/nXxQX07OstLS0eJcQFno3cdG79K5VBdO7ER/oDx48KC0tLZKdna3dn52dLfX19aesX1paKk6n07+4XK5Il4QYsfpXfvRu4qJ36V2rCqZ3475Tas6cOeL1ev1LXV1dvEsCgkLvwqro3cTyk0i/YM+ePaVTp07i8Xi0+z0ej+Tk5JyyvsPhEIfDEekygJDRu7AqeheBRHyLPjU1VfLz86W8vNx/X2trq5SXl0thYWGk3w6IGHoXVkXvIqCOH+PZtpUrVyqHw6HKysrUrl271LRp01RGRoaqr69v97lerzfuRzGydGzxer3RaKeYoncTc6F36V2rLsH0blQGeqWUWrRokXK5XCo1NVUNGzZMbdu2Lajn0XDWXezwy1IpejcRF3qX3rXqEkzvRmXCnHD4fD5xOp3xLgMd4PV6JT09Pd5lxA29a130Lr1rVcH0btyPugcAANHDQA8AgI1F/PQ6AOb085//XMtdunTR8oUXXqjlm266qc3XeuGFF7RsnH3t1Vdf7UiJAKKALXoAAGyMgR4AABtjoAcAwMbYRw/Y1KpVq7QcaJ/76bS2trb52L333qvlk6+aJiKyefNmLdfW1ob03kCsnHPOOVr+/PPPtXz//fdredGiRVGvKdLYogcAwMYY6AEAsDG+ugdsItyv6o1fWf7P//yP//aZZ56pPTZ+/HgtDxgwQMuTJ0/WcmlpaUi1ALFy8cUXa9m4y+rbb7+NZTlRwRY9AAA2xkAPAICNMdADAGBj7KMHLGro0KFanjhxYsD1d+7cqeXrr79eywcPHtTyoUOH/LdTU1O1x7Zt26blIUOGaLlHjx4BawHM4qKLLtLy4cOHtbxmzZoYVhMdbNEDAGBjDPQAANgYAz0AADaWcPvojecWT506Vcv79u3T8rFjx7T8pz/9Scv19fVa3rNnT7glAkHp3bu3lpOSkrRs3CdfXFys5f379wf9Xg8++KCWzzvvvIDrv/vuu0G/NhBLgwcP1nJJSYmW7XiJZbboAQCwMQZ6AABsjIEeAAAbS7h99AsWLNBy//79Q3q+8fKcjY2NWjbuF40l45zMxn9rZWVlLMtBlL3zzjtaPuuss7Rs7M3vv/++w+912223aTklJaXDrwXE08CBA7XctWtXLRuvGWEHbNEDAGBjDPQAANgYAz0AADaWcPvojefNX3jhhVrevXu3lgcNGqTlSy65RMtjx47V8ogRI7RcV1fnv923b9+Qaj1x4oSWDxw4oGXjedRGtbW1WmYfvb198803EX29hx56yH/7nHPOCbju9u3bA2bALB5++GEtG//f2PH3JFv0AADYGAM9AAA2FvJAv2XLFhk/frzk5uZKUlKSrF27VntcKSVPPPGE9O7dW7p06SJFRUXy5ZdfRqpeoMPoXVgVvYtwhLyP/vDhwzJkyBC5++675cYbbzzl8QULFshzzz0nL7/8suTl5cnjjz8uxcXFsmvXLuncuXNEig5HeXl5wGy0fv36gI93795dy8ZrG1dVVflvFxQUBFHh/zHOs//FF19o2Xg8QWZmppa/+uqrkN7P7qzeu9F23XXXaXn+/Pn+28br0X/33XdanjNnjpaPHDkS4eoSG73bcca5UoYOHapl4+9V4/Xo7SDkgX7cuHEybty40z6mlJKFCxfK3Llz5YYbbhARkVdeeUWys7Nl7dq1p0y6ISLS1NQkTU1N/uzz+UItCQgKvQuroncRjojuo9+7d6/U19dLUVGR/z6n0ynDhw+XioqK0z6ntLRUnE6nfwn1yHQgEuhdWBW9i/ZEdKD/8ZKt2dnZ2v3Z2dmnXM71R3PmzBGv1+tfTj4dDYgVehdWRe+iPXE/j97hcIjD4Yh3GR32ww8/aHnjxo1trtve8QDtmTRpkpaNxwf87//+r5btOGezmVi9d42M+y6N++VPZuytzZs3R6UmRIfdejeQyy67LODjxvlJ7CiiW/Q5OTkiIuLxeLT7PR6P/zHAjOhdWBW9i/ZEdKDPy8uTnJwcbcvV5/PJ9u3bpbCwMJJvBUQUvQuronfRnpC/uj906JDs2bPHn/fu3Ss7duyQzMxMcblcMmvWLHnqqafk7LPP9p/mkZubKxMmTIhk3UDI6F1YFb2LcIQ80FdWVsrll1/uz7NnzxYRkSlTpkhZWZk8/PDDcvjwYZk2bZo0NDTI6NGjZf369Ql/LmdHZGVlaXnJkiVaTk7Wv5A5+bxnkfCuP25H9K7OOOnKVVdd1ea6r7zyipbnzp0bjZLQBnq34y644IKAjy9YsCBGlcRPyAP92LFjRSnV5uNJSUkyf/78UwYdIN7oXVgVvYtwMNc9AAA2xkAPAICNxf08erTN7XZruVevXlo2nsNfU1MT9ZpgXb1799byyJEjtWw8r/rgwYP+20899ZT22KFDhyJcHRA5I0aM8N++6667tMc++eQTLX/wwQcxqSme2KIHAMDGGOgBALAxvro3kVGjRmn5kUceCbi+8RzZ6urqSJcEG3njjTe03KNHj4Drv/baa/7bXPIYVnLyBX6Ml+82XnrceDlwO2KLHgAAG2OgBwDAxhjoAQCwMfbRm8g111yj5ZSUFC0bL3NbUVER9ZpgXddff72WL7nkkoDrb9q0Scvz5s2LdElATAwZMsR/2zij4Ouvvx7rcuKOLXoAAGyMgR4AABtjoAcAwMbYRx9HXbp00fLVV1+t5ebmZi0b95keP348OoXBkoznxT/66KNaNh7zYbRjxw4tM80trCInJ0fLl156qf+2cWrwNWvWxKQmM2GLHgAAG2OgBwDAxhjoAQCwMfbRx9FDDz2k5YsvvljLxjmZP/roo6jXBOt68MEHtVxQUBBw/bVr12qZ8+ZhVXfeeaeWs7Ky/Lf/8pe/xLga82GLHgAAG2OgBwDAxhjoAQCwMfbRx9C1116r5ccff1zLPp9Py/Pnz496TbCP2bNnh7R+SUmJljlvHlbVr1+/Nh/74YcfYliJObFFDwCAjTHQAwBgYwz0AADYGPvoo+zk+cefe+457bFOnTpp+b333tPytm3bolcYEl5mZqaWw7l2gtfrDfhaxnn2nU5nwNfLyMjQcijHH7S0tGj5F7/4hZaPHDkS9GvBGq677ro2H3vnnXdiWIk5sUUPAICNMdADAGBjIQ30paWlUlBQIGlpaZKVlSUTJkw45RKAx44dE7fbLT169JBu3brJpEmTxOPxRLRoIFT0LqyK3kW4QtpHv3nzZnG73VJQUCAnTpyQRx99VK666irZtWuXdO3aVUREHnjgAXn33Xdl9erV4nQ6paSkRG688Ub58MMPo/IPMBvjfveT56vPy8vTHvvqq6+0bDyvHpFD757qs88+i9hrrV69Wsv79+/XcnZ2tpZvvfXWiL13e+rr67X861//OmbvHQn07qlGjx6tZeP16KELaaA3XmSlrKxMsrKypKqqSsaMGSNer1defPFFWb58uVxxxRUiIrJs2TIZNGiQbNu2TUaMGHHKazY1NUlTU5M/GyeNASKB3oVV0bsIV1j76H880vbHo3erqqrk+PHjUlRU5F9n4MCB4nK5pKKi4rSvUVpaKk6n07/07ds3nJKAoNC7sCp6F6Hq8EDf2toqs2bNklGjRsngwYNF5N9fkaWmpp5yakx2dvYpX5/9aM6cOeL1ev1LXV1dR0sCgkLvwqroXXREh8+jd7vdUl1dLVu3bg2rAIfDIQ6HI6zXMJMBAwZoOT8/v811jecGG/fZIzrs2rvGeRhuuOGGmL33zTffHNbzT5w4oeXW1taA67/99tv+25WVlQHX/dvf/tbxwkzGrr0bqokTJ2rZeGzUJ5984r+9ZcuWmNRkZh3aoi8pKZF169bJxo0bpU+fPv77c3JypLm5WRoaGrT1PR4PB0vAFOhdWBW9i44KaaBXSklJSYmsWbNGNmzYcMpR5Pn5+ZKSkiLl5eX++2pqaqS2tlYKCwsjUzHQAfQurIreRbhC+ure7XbL8uXL5a233pK0tDT//h+n0yldunQRp9Mp99xzj8yePVsyMzMlPT1dZs6cKYWFhac98hOIFXoXVkXvIlxJSikV9MpJSae9f9myZXLnnXeKyL8nbnjwwQdlxYoV0tTUJMXFxbJkyZKgv0Ly+XztzoNtJsbrIG/evFnLLpfLf/uhhx7SHnvmmWe0HMKPwpS8Xq+kp6fHu4zTSsTeffjhh7VsnG++Peeff77/dqjnvb/00kta/vrrrwOu/8Ybb2j5888/D+n9wkXvmqt3jc444wwtV1VVafncc8/V8mOPPea/XVpaGr3CTCCY3g1piz6Ygahz586yePFiWbx4cSgvDUQVvQuroncRLua6BwDAxhjoAQCwMa5HH6Zp06Zp+eR98kbG/fdW3ycPc1uwYEHEXuv222+P2GsBoTp+/LiWf/jhBy2fPK+CiMjvf//7qNdkJWzRAwBgYwz0AADYGF/dh8h4ecSZM2fGqRIASAzGr+5HjhwZp0qsiS16AABsjIEeAAAbY6AHAMDG2EcfoksvvVTL3bp1C7j+yZeePXToUFRqAgCgLWzRAwBgYwz0AADYGAM9AAA2xj76CPv000+1fOWVV/pvf//997EuBwCQ4NiiBwDAxhjoAQCwMQZ6AABsLEmZ7FqpPp9PnE5nvMtAB3i9XklPT493GXFD71oXvUvvWlUwvcsWPQAANsZADwCAjZluoDfZngSEINF/don+77eyRP/ZJfq/38qC+dmZbqBvbGyMdwnooET/2SX6v9/KEv1nl+j/fisL5mdnuoPxWltbZd++faKUEpfLJXV1dQl9kEyofD6f9O3bN6afm1JKGhsbJTc3V5KTTfe3Y8zQu+Ghd+OH3g2P2XvXdDPjJScnS58+fcTn84mISHp6Og3XAbH+3Dhil96NFHo39ujdyDBr7ybun7AAACQABnoAAGzMtAO9w+GQefPmicPhiHcplsLnFn/8DDqGzy3++Bl0jNk/N9MdjAcAACLHtFv0AAAgfAz0AADYGAM9AAA2xkAPAICNMdADAGBjph3oFy9eLP3795fOnTvL8OHD5eOPP453SaZRWloqBQUFkpaWJllZWTJhwgSpqanR1jl27Ji43W7p0aOHdOvWTSZNmiQejydOFScWerdt9K650btts3TvKhNauXKlSk1NVS+99JLauXOnmjp1qsrIyFAejyfepZlCcXGxWrZsmaqurlY7duxQ11xzjXK5XOrQoUP+daZPn6769u2rysvLVWVlpRoxYoQaOXJkHKtODPRuYPSuedG7gVm5d0050A8bNky53W5/bmlpUbm5uaq0tDSOVZnXd999p0REbd68WSmlVENDg0pJSVGrV6/2r7N7924lIqqioiJeZSYEejc09K550LuhsVLvmu6r++bmZqmqqpKioiL/fcnJyVJUVCQVFRVxrMy8vF6viIhkZmaKiEhVVZUcP35c+wwHDhwoLpeLzzCK6N3Q0bvmQO+Gzkq9a7qB/uDBg9LS0iLZ2dna/dnZ2VJfXx+nqsyrtbVVZs2aJaNGjZLBgweLiEh9fb2kpqZKRkaGti6fYXTRu6Ghd82D3g2N1XrXdJepRWjcbrdUV1fL1q1b410KEBJ6F1Zltd413RZ9z549pVOnTqccqejxeCQnJydOVZlTSUmJrFu3TjZu3Ch9+vTx35+TkyPNzc3S0NCgrc9nGF30bvDoXXOhd4Nnxd413UCfmpoq+fn5Ul5e7r+vtbVVysvLpbCwMI6VmYdSSkpKSmTNmjWyYcMGycvL0x7Pz8+XlJQU7TOsqamR2tpaPsMoonfbR++aE73bPkv3brSO8nv++edVv379lMPhUMOGDVPbt28P+rkrV65UDodDlZWVqV27dqlp06apjIwMVV9fH61yLWXGjBnK6XSqTZs2qf379/uXI0eO+NeZPn26crlcasOGDaqyslIVFhaqwsLCOFZtHfRu9NC70UXvRo+Vezcql6ldtWqV3HHHHbJ06VIZPny4LFy4UFavXi01NTWSlZUV8Lmtra2yb98+Wb58uSxatEg8Ho9ceOGFsmDBAhk6dGikS7Ukp9N52vuXLFkikydPFpF/T9zw2GOPyeuvvy5NTU1y5ZVXyjPPPHPKwTaRoJSSxsZGyc3NleRk031JFBJ6N7ro3eihd6PL0r0bjb8ewjkfs66uTokIiwWXurq6aLRTTNG7ibnQu/SuVZdgejfif8KGej5mU1OT+Hw+/6Ii/wUDYiQtLS3eJYSF3k1c9C69a1XB9G7EB/pQz8csLS0Vp9PpX1wuV6RLQowkJSXFu4Sw0LuJi96ld60qmN6N+06pOXPmiNfr9S91dXXxLgkICr0Lq6J3E0vEJ8wJ9XxMh8MhDocj0mUAIaN3YVX0LgKJ+BY952PCquhdWBW9i4A6foxn28I5H9Pr9cb9KEaWji1erzca7RRT9G5iLvQuvWvVJZjejdqEOYsWLVIul0ulpqaqYcOGqW3btgX1PBrOuosdflkqRe8m4kLv0rtWXYLp3ahMmBMOn8/X5sQEMDev1yvp6enxLiNu6F3ronfpXasKpnfjftQ9AACIHgZ6AABsjIEeAAAbY6AHAMDGGOgBALAxBnoAAGyMgR4AABuL+Fz3ia5r165a/s1vfuO/fe+992qPVVVVafnmm2/W8jfffBPh6gAAiYYtegAAbIyBHgAAG+Or+wjr3bu3lqdOneq/3draqj2Wn5+v5euuu07LixcvjnB1SGSXXHKJlt98800t9+/fP2a1XHXVVVrevXu3lrk+OmJl/PjxWn777be1XFJSouWlS5dquaWlJTqFRRBb9AAA2BgDPQAANsZADwCAjbGPPky9evXS8ssvvxynSoDAiouLtexwOOJUyan7Re+++24t33bbbbEsBwmkR48eWl6yZEnA9Z9//nktv/TSS1o+evRoZAqLIrboAQCwMQZ6AABsjIEeAAAbYx99iH72s59pecKECVoeNmxYh197zJgxWk5O1v8O+/TTT7W8ZcuWDr8X7O8nP9H/e19zzTVxquRUxumfZ8+erWXjVNKHDx+Oek1IDMbfs3369Am4/ooVK7R87NixiNcUbWzRAwBgYwz0AADYGAM9AAA2xj76ED377LNaNs5fH44bb7wxYDZetvbWW2/VsnG/JxLb5ZdfruXCwkItL1iwIJblaLp3767l8847T8tnnHGGltlHj44yzhfx2GOPhfT8V199VctKqbBrijW26AEAsDEGegAAbIyBHgAAG2MffTvee+89LRvPbQ/Hv/71Ly0fOnRIy/369dNyXl6elj/++GMtd+rUKWK1wXoGDx6sZeP5v1999ZWWn3766ajX1JYbbrghbu+NxHLBBRdoOT8/P+D6J06c0PJf/vKXiNcUa2zRAwBgYyEP9Fu2bJHx48dLbm6uJCUlydq1a7XHlVLyxBNPSO/evaVLly5SVFQkX375ZaTqBTqM3oVV0bsIR8gD/eHDh2XIkCGyePHi0z6+YMECee6552Tp0qWyfft26dq1qxQXF1ty2kDYC70Lq6J3EY6Q99GPGzdOxo0bd9rHlFKycOFCmTt3rn8f3CuvvCLZ2dmydu1aS1xj+rLLLtPyueeeq2XjefOhnEe/dOlSLb///vta9nq9Wr7iiiu03N75nzNmzNDyCy+8EHRticDuvTt37lwtG+eLv/rqq7VsPCYkmjIzM7Vs/H8Wyfko7MjuvRtNkyZNCml94+9lO4joPvq9e/dKfX29FBUV+e9zOp0yfPhwqaioOO1zmpqaxOfzaQsQa/QurIreRXsiOtDX19eLiEh2drZ2f3Z2tv8xo9LSUnE6nf6lb9++kSwJCAq9C6uid9GeuB91P2fOHPF6vf6lrq4u3iUBQaF3YVX0bmKJ6Hn0OTk5IiLi8Xikd+/e/vs9Ho9cdNFFp32Ow+E4ZS7iWOrfv7+WV65cqeWePXuG9HrG+ejfeOMN/+1f/vKX2mNHjhwJ6bWmTZum5V69emnZOHd5586dtfz8889r+fjx4wHfP5FYsXdvuukmLRuvN79nzx4tV1ZWRr2mthiPLzHuk9+0aZOWGxoaolyRfVixd2PJeP15o+bmZi2HOhe+FUR0iz4vL09ycnKkvLzcf5/P55Pt27efckENwEzoXVgVvYv2hLxFf+jQIW1LYe/evbJjxw7JzMwUl8sls2bNkqeeekrOPvtsycvLk8cff1xyc3NlwoQJkawbCBm9C6uidxGOkAf6yspK7fKXs2fPFhGRKVOmSFlZmTz88MNy+PBhmTZtmjQ0NMjo0aNl/fr1p3yNDMQavQuroncRjiRlsovr+nw+cTqdMXu/s846S8u7d+8OuL5xrvuNGzdq2XjO6sGDB8OoTjdz5kwtP/PMMwFrM+4HHThwoJaNc5+Hy+v1Snp6ekRf00pi3burVq3SsvF8YWO/xHJeBeOxL9u2bdOy8bz64uJiLRv/X0UbvRvb3o22kSNH+m9/+OGHAdf94YcftGzsTbMLpnfjftQ9AACIHgZ6AABsjIEeAAAb43r0ITKei3z33XdrOZL75I3efvttLU+ePFnLBQUFUXtvxJ9xH+qIESMCrh/Pax0Y53wwzkdhPBYm1vvkYW+h/C5MhGuCsEUPAICNMdADAGBjfHVvYDxFzWj48OExquRUSUlJWjbW2l7tTz75pJZ/+tOfRqQuxIZxytL/9//+n5ZXrFgRy3ICGjBgQMDHq6urY1QJEtHQoUPbfMw4vTJf3QMAAEtjoAcAwMYY6AEAsLGE30c/ffp0LRunjTWT8ePHa/niiy/WsrF2Yzbuo4e1NDY2annHjh1avvDCC7VsnMrz+++/j0pdIiJZWVlaNl5C12jr1q1RqwWJZ/To0Vq+/fbb21zX6/Vq+dtvv41KTWbCFj0AADbGQA8AgI0x0AMAYGMJv4/euN87nnr16qXl8847T8uPPvpoSK934MABLR8/frxjhcEUjh49qmXjZYaNl6l99913tWy8rHEoBg8erOUzzzxTy8bL0rZ39WszHwsD6+nRo4eWA80p8sEHH0S7HNNhix4AABtjoAcAwMYY6AEAsLGE30dvJo899piW3W53SM//+uuvtTxlyhQt19bWdqgumNO8efO0bLwWwrXXXqvlcObCN15+2bgP3ngZ2vaUlZV1uBbAKNC8Dca57f/rv/4rytWYD1v0AADYGAM9AAA2xkAPAICNsY8+jt577z0tn3vuuWG93q5du7TMfOL29vnnn2v5lltu0fJFF12k5bPOOqvD7/X6668HfPzll1/W8uTJkwOub5wTAAhFnz59tBxobnvjXPaVlZVRqcnM2KIHAMDGGOgBALAxBnoAAGws4ffRG889DjRHsojIuHHjAj7+hz/8Qcu5ubltrmt8r3Dn/zbTvP2IP+P16o05kv75z3+GtL5x7vzq6upIlgObGzlypJYD/d5eu3ZtlKsxP7boAQCwsZAG+tLSUikoKJC0tDTJysqSCRMmSE1NjbbOsWPHxO12S48ePaRbt24yadIk8Xg8ES0aCBW9C6uidxGukAb6zZs3i9vtlm3btskHH3wgx48fl6uuukoOHz7sX+eBBx6Qd955R1avXi2bN2+Wffv2yY033hjxwoFQ0LuwKnoX4UpS7V04OoADBw5IVlaWbN68WcaMGSNer1d69eoly5cv9889/Pnnn8ugQYOkoqJCRowY0e5r+nw+cTqdHS0pZA888ICWFyxYEHD9SO5XD/e1li5dquWZM2d2uJZI8Hq9kp6eHtcagmWH3jWTJ598UsuPP/54wPU7deoUxWpCR+9aq3dnzJih5SVLlmj55GszDBo0qM3H7CCY3g1rH73X6xURkczMTBERqaqqkuPHj0tRUZF/nYEDB4rL5ZKKiorTvkZTU5P4fD5tAaKN3oVV0bsIVYcH+tbWVpk1a5aMGjXKfwRtfX29pKamSkZGhrZudna21NfXn/Z1SktLxel0+pe+fft2tCQgKPQurIreRUd0eKB3u91SXV0tK1euDKuAOXPmiNfr9S91dXVhvR7QHnoXVkXvoiM6dB59SUmJrFu3TrZs2aLNOZyTkyPNzc3S0NCg/XXp8XgkJyfntK/lcDjE4XB0pIyIePPNN7X80EMPablXr14xq+XAgQNa3r17t5anTZum5f3790e9JruxU++aifFQnzAO/UEb6N3/U1xcHPDx2tpa/+0fd3UkspC26JVSUlJSImvWrJENGzZIXl6e9nh+fr6kpKRIeXm5/76amhqpra2VwsLCyFQMdAC9C6uidxGukLbo3W63LF++XN566y1JS0vz7/9xOp3SpUsXcTqdcs8998js2bMlMzNT0tPTZebMmVJYWBjUkZ9AtNC7sCp6F+EKaaB/4YUXRERk7Nix2v3Lli2TO++8U0REnn32WUlOTpZJkyZJU1OTFBcXn3LqAxBr9C6sit5FuMI6jz4a4n0+55gxY7Q8YcIELd9///1ajuR59D/72c+0vHjx4g6/djxY6VzkaIh378ZTaWmplo3HuhivP5+Wlhb1mkJB75q7d1NSUrT8j3/8Q8vGayd89NFH/tujRo2KXmEmEPXz6AEAgLkx0AMAYGMM9AAA2FjCX4/eaMuWLQHz+++/r2Xjue3Ga8K//fbb/tvGa9UnJSVpedeuXaEVC5jEXXfdpeWGhgYt/+pXv4phNbAb47FQlZWVWjbuo9+zZ0/Ua7IStugBALAxBnoAAGyMr+5DtH79+oAZSER///vftfzMM89oeePGjbEsBzbT0tKi5ccee0zLxrPEq6qqol6TlbBFDwCAjTHQAwBgYwz0AADYGFPgImKYRpTetSp6l961KqbABQAgwTHQAwBgYwz0AADYGAM9AAA2xkAPAICNMdADAGBjDPQAANgYAz0AADbGQA8AgI0x0AMAYGOmG+hNNiMvQpDoP7tE//dbWaL/7BL9329lwfzsTDfQNzY2xrsEdFCi/+wS/d9vZYn+s0v0f7+VBfOzM91FbVpbW2Xfvn2ilBKXyyV1dXUJfbGJUPl8Punbt29MPzellDQ2Nkpubq4kJ5vub8eYoXfDQ+/GD70bHrP37k9iUlEIkpOTpU+fPuLz+UREJD09nYbrgFh/blz5it6NFHo39ujdyDBr7ybun7AAACQABnoAAGzMtAO9w+GQefPmicPhiHcplsLnFn/8DDqGzy3++Bl0jNk/N9MdjAcAACLHtFv0AAAgfAz0AADYGAM9AAA2xkAPAICNmXagX7x4sfTv3186d+4sw4cPl48//jjeJZlGaWmpFBQUSFpammRlZcmECROkpqZGW+fYsWPidrulR48e0q1bN5k0aZJ4PJ44VZxY6N220bvmRu+2zdK9q0xo5cqVKjU1Vb300ktq586daurUqSojI0N5PJ54l2YKxcXFatmyZaq6ulrt2LFDXXPNNcrlcqlDhw7515k+fbrq27evKi8vV5WVlWrEiBFq5MiRcaw6MdC7gdG75kXvBmbl3jXlQD9s2DDldrv9uaWlReXm5qrS0tI4VmVe3333nRIRtXnzZqWUUg0NDSolJUWtXr3av87u3buViKiKiop4lZkQ6N3Q0LvmQe+Gxkq9a7qv7pubm6WqqkqKior89yUnJ0tRUZFUVFTEsTLz8nq9IiKSmZkpIiJVVVVy/Phx7TMcOHCguFwuPsMoondDR++aA70bOiv1rukG+oMHD0pLS4tkZ2dr92dnZ0t9fX2cqjKv1tZWmTVrlowaNUoGDx4sIiL19fWSmpoqGRkZ2rp8htFF74aG3jUPejc0Vutd0129DqFxu91SXV0tW7dujXcpQEjoXViV1XrXdFv0PXv2lE6dOp1ypKLH45GcnJw4VWVOJSUlsm7dOtm4caP06dPHf39OTo40NzdLQ0ODtj6fYXTRu8Gjd82F3g2eFXvXdAN9amqq5OfnS3l5uf++1tZWKS8vl8LCwjhWZh5KKSkpKZE1a9bIhg0bJC8vT3s8Pz9fUlJStM+wpqZGamtr+QyjiN5tH71rTvRu+yzdu3E9FLANK1euVA6HQ5WVlaldu3apadOmqYyMDFVfXx/v0kxhxowZyul0qk2bNqn9+/f7lyNHjvjXmT59unK5XGrDhg2qsrJSFRYWqsLCwjhWnRjo3cDoXfOidwOzcu9GbaB//vnnVb9+/ZTD4VDDhg1T27dvD+n5ixYtUi6XS6Wmpqphw4apbdu2RalS6xGR0y7Lli3zr3P06FF13333qe7du6szzjhDTZw4Ue3fvz9+RVsIvRs99G500bvRY+XejcplaletWiV33HGHLF26VIYPHy4LFy6U1atXS01NjWRlZQV8bmtrq+zbt0/S0tIkKSkp0qUhCpRS0tjYKLm5uZKcbLq9QSGhdxMLvftv9K71hNS70fjrIZyJF+rq6tr8y4nF3EtdXV002imm6N3EXOhdeteqSzC9G/E/YUOdeKGpqUl8Pp9/UZH/ggExkpaWFu8SwkLvJi56l961qmB6N+IDfagTL5SWlorT6fQvLpcr0iUhRqz+lR+9m7joXXrXqoLp3bjvlJozZ454vV7/UldXF++SgKDQu7AqejexRHxmvFAnXnA4HOJwOCJdBhAyehdWRe8ikIhv0TPxAqyK3oVV0bsIqOPHeLYtnIkXvF5v3I9iZOnY4vV6o9FOMUXvJuZC79K7Vl2C6d2oTZjT0YkXaDjrLnb4ZakUvZuIC71L71p1CaZ3ozJhTjh8Pp84nc54l4EO8Hq9kp6eHu8y4obetS56l961qmB6N+5H3QMAgOhhoAcAwMYY6AEAsDEGegAAbIyBHgAAG2OgBwDAxiI+BS4AAFbVvXt3LYd6wZ9vvvlGyw888ICWq6ur/be/+OIL7bFPP/00pPcKFlv0AADYGAM9AAA2xlf37cjKytLyn//8Zy1/9NFHWv7DH/6g5a+//joqdQXDONPVmDFjtLx+/Xr/7ePHj8ekJgCIp2uvvVbL119/vZbHjh2r5bPOOiuk1zd+Hd+vXz8tB7pqYKdOnUJ6r2CxRQ8AgI0x0AMAYGMM9AAA2Bj76A2Mp1bs3LlTy8b93h6PR8tm2idfVVWl5V69emk5Pz/ff3vPnj3RKwymZLziVWlpqZYHDx7sv11UVKQ9xjEdMJMBAwZo2e12+29PnTpVe6xLly5aTkpKimgt55xzTkRfLxLYogcAwMYY6AEAsDEGegAAbCzh99H37NlTy6tWrdJyZmamlpcsWaLlmTNnRqewDpg7d66W8/LytHzvvfdqmf3yiWXy5Mla/vWvf63lvn37tvlc4/78f/3rX5ErDAhTnz59tHz//ffH7L0///xzLRuP6zIDtugBALAxBnoAAGyMgR4AABtL+H30l1xyiZaN8xwbzZ8/P4rVhOb888/X8oMPPqjlNWvWaNl4/AHszbjfcuHChVru0aOHlpVSbb7WokWLtFxSUqLl77//vgMVAv9mPFbKuI/9ww8/1PLJ1+kQEWlqatKy1+v13z58+LD2WNeuXbX8/vvva/nky8iKiGzfvl3Ln3zyiZaPHj2qZeP7mQFb9AAA2BgDPQAANsZADwCAjSXcPnrj9eUnTZoUcP177rlHywcOHIh4TcEy7pP/61//GnB94z76xsbGiNcE8/r5z3+uZeOcEKG49dZbtXz11Vdr2XhOvnGffnNzc4ffG/bT3n7yIUOGaHnixIkBX2/btm1aPvnYK+P1R1wul5a//fZbLbe2tgZ8Lytiix4AABtjoAcAwMZCHui3bNki48ePl9zcXElKSpK1a9dqjyul5IknnpDevXtLly5dpKioSL788stI1Qt0GL0Lq6J3EY6Q99EfPnxYhgwZInfffbfceOONpzy+YMECee655+Tll1+WvLw8efzxx6W4uFh27dolnTt3jkjR4fjd736n5f/8z//UsvEa7qtXr456TcG69NJLtZydna3lsrIyLb/22mvRLslSrN677enXr5+W77rrroDrf/bZZ1r2eDxaNl6D/mROp1PLxuMB/vSnP2m5vr4+YC0IzOq9m5qaquXly5dr2bhP/umnn9Zye8cjGRn3y5+strY2pNeyg5AH+nHjxsm4ceNO+5hSShYuXChz586VG264QUREXnnlFcnOzpa1a9fKbbfddspzmpqatMkOfD5fqCUBQaF3YVX0LsIR0X30e/fulfr6em1LwOl0yvDhw6WiouK0zyktLRWn0+lfAl1BC4gWehdWRe+iPREd6H/8es74lXJ2dnabX93NmTNHvF6vf6mrq4tkSUBQ6F1YFb2L9sT9PHqHwyEOhyNm72ecz9t4zuS+ffu0HMvzf7t06aLlRx99VMv33Xeflo3/lrvvvjs6heG0Yt277bnooou0nJaWpuW//e1vWr7sssu0bNyX+x//8R/+28ZeHDBggJZzcnK0/NZbb2nZ+LUzc+PHV7R7t1u3blqeM2eOlq+77jotHzx4UMu//e1vtXzkyJEIVpd4IrpF/+N/duNBPR6P55RfBICZ0LuwKnoX7YnoQJ+Xlyc5OTlSXl7uv8/n88n27dulsLAwkm8FRBS9C6uid9GekL+6P3TokOzZs8ef9+7dKzt27JDMzExxuVwya9Yseeqpp+Tss8/2n+aRm5srEyZMiGTdQMjoXVgVvYtwhDzQV1ZWyuWXX+7Ps2fPFhGRKVOmSFlZmTz88MNy+PBhmTZtmjQ0NMjo0aNl/fr1pjiXMxjXXnutlo1zMDc0NGj5hRde6PB7GfeRjh07VssjRowI+PzXX3+9w++diOzeu8Z9rsZjOJ599tmAzz927JiWly1b5r998803a4+deeaZAV/LuE+Vue7DY7XeNf6B8cgjj2jZeC67cY6Qk68nj/CFPNCPHTv2lF8gJ0tKSpL58+fL/PnzwyoMiDR6F1ZF7yIczHUPAICNMdADAGBjcT+PPtZ+//vfa/nk/V4iIrm5uVoeM2aMlpOSkrR8/fXXd7gW42sF+mpOROSf//ynlo3nNiOxnXze++kYjz8xXhglkKFDh4ZUi/H64IcOHQrp+bC2kSNHBnz8k08+0bLxmvCILLboAQCwMQZ6AABsLOG+ujdehvbCCy/UsnEa0auvvlrLDz30kJYPHDig5ZdffjnoWl599VUtf/rppwHX/+ijj7T81VdfBf1esL8VK1Zo2bhbqaCgQMsDBw7U8gUXXKDliRMn+m93795de8x4mqnx8alTp2rZ2Ou7du0S2NdNN90U8HHj79V58+Zp2TiF8o4dOyJSV6Jiix4AABtjoAcAwMYY6AEAsLEk1d45XTHm8/nE6XTGu4yYME4jevJc1iKn7pcqLi7WsvH4gHjzer2Snp4e7zLiJt69m5mZqWVjPxlrC+X0zr/+9a9adrvdWl63bp2Wzz77bC3/8Y9/1PL06dPbfK94oHcj27vtXQ68Pcb1ly5dqmXj6Zsul0vLJ/f+zp07A77X+eefr+WKigotm/3Uv2B6ly16AABsjIEeAAAbY6AHAMDGEu48ejN54okntGzcr/WLX/xCy2bbJw9z+f7777V8yy23aNl4WeP29skuWrTIf9vYi8ZL2r755ptaNl6W1Hh8yYABA7TMnBD28tvf/lbLP15WN1jJyfo26H333RcwR5Lx9+ymTZu0fNttt0XtvaOFLXoAAGyMgR4AABtjoAcAwMY4jz6Gbr75Zi2vWrVKy42NjVo2XkL3H//4R3QKixDORTZ37xYVFWn59ttv17Jx/vqTjyFp7zKzXbp00fLy5cu1bJx3/7XXXtPylClTAr5+tNG7ke3dTp06afniiy/WsrE/fvIT/XCxvn37atm4zz6WjEPkk08+qeWnnnoqhtWcivPoAQBIcAz0AADYGAM9AAA2xnn0MTRu3LiAjxvnCzf7PnlYi3G+emMOx9GjR7VsPP7EuI/eePyJcZ5+45wAsJaWlhYtV1ZWavmcc84J+Pwrr7xSyykpKVo27icvKCgIscLgGa8JkZ+fH7X3iha26AEAsDEGegAAbIyBHgAAG2MffQwZ99EfPnxYy7/73e9iWQ4QNX/+85+1bNxHf+utt2q5pKREy/Pnz49OYbCE8vLygI9fdNFFWjbuoz9x4oT/9rJly7TH/vjHP2p51qxZWjbOL2EHbNEDAGBjDPQAANhYSAN9aWmpFBQUSFpammRlZcmECROkpqZGW+fYsWPidrulR48e0q1bN5k0aZJ4PJ6IFg2Eit6FVdG7CFdIc91fffXVctttt0lBQYGcOHFCHn30UamurpZdu3ZJ165dRURkxowZ8u6770pZWZk4nU4pKSmR5ORk+fDDD4N6D7PPFx6q6dOn+28vWbJEe+y7777Tck5OTkxqihYzzxdO78aXcZ+q8TPt3LmzlgcNGqTlL774Iip1/YjetVbvXnLJJVr++9//HvRzN27cqOWxY8dq2XjevJHx9/jMmTODfu9oCKZ3QzoYb/369VouKyuTrKwsqaqqkjFjxojX65UXX3xRli9fLldccYWI/PtAiEGDBsm2bdtkxIgRp7xmU1OTNDU1+bPP5wulJCAo9C6sit5FuMLaR+/1ekXk/2a1qqqqkuPHj2tXyRo4cKC4XC6pqKg47WuUlpaK0+n0L8arFgHRQO/CquhdhKrDA31ra6vMmjVLRo0aJYMHDxYRkfr6eklNTZWMjAxt3ezsbKmvrz/t68yZM0e8Xq9/qaur62hJQFDoXVgVvYuO6PB59G63W6qrq2Xr1q1hFeBwOMThcIT1GmZ28j564+EQ7777bsDnpqWlabl79+5arq2tDbO6xETvxt6OHTu0fPK17kVEfvOb32j56aef1vJPf/pTLRvn1k8U9O6/7d69W8vGeRtuueWWNp9rvM6CkXGefuPv6UceeSSYEk2lQ1v0JSUlsm7dOtm4caP06dPHf39OTo40NzdLQ0ODtr7H47H8gWawB3oXVkXvoqNCGuiVUlJSUiJr1qyRDRs2SF5envZ4fn6+pKSkaLMa1dTUSG1trRQWFkamYqAD6F1YFb2LcIX01b3b7Zbly5fLW2+9JWlpaf79P06nU7p06SJOp1PuuecemT17tmRmZkp6errMnDlTCgsLT3vkJxAr9C6sit5FuEI6j76t8wuXLVsmd955p4j8e+KGBx98UFasWCFNTU1SXFwsS5YsCforJKudz9mek/dNXnDBBdpjL774opY3b96s5QceeEDLO3fu1PKUKVMiUGHkmPlcZHrXXHr16qVl4/neZ511lpaN5+F/9tlnEa2H3rV272ZnZ2v5v//7v/23hw4dqj2WlZWl5a+//lrLr776qpaffPLJ8AuMooifRx/M3wSdO3eWxYsXy+LFi0N5aSCq6F1YFb2LcDHXPQAANsZADwCAjYW0jz4WrL6vyCjQPnrjvjfjj8K4D/9Xv/qVls02yYWZ93PGgt16N5ZcLpeWjftNV6xYoeXJkydH9P3pXfv2rnEOBuMBir/85S+1bLwGidkF07ts0QMAYGMM9AAA2Bhf3UfZ6NGj/bfnz5+vPbZlyxYtv/DCC1r+4YcftNzc3Bzh6iKLrz/t1bvx9P7772vZOPHL8OHD/bd37doV9vvRu/SuVfHVPQAACY6BHgAAG2OgBwDAxjp8mVoE5+TLSV5xxRVxrASwjptuuknLn376qZZPniI3EvvoATtjix4AABtjoAcAwMYY6AEAsDH20QMwHZ/Pp+W8vLw4VQJYH1v0AADYGAM9AAA2xkAPAICNMdADAGBjDPQAANgYAz0AADZmuoHeZFfNRQgS/WeX6P9+K0v0n12i//utLJifnekG+sbGxniXgA5K9J9dov/7rSzRf3aJ/u+3smB+dknKZH/Ktba2yr59+0QpJS6XS+rq6iQ9PT3eZVmGz+eTvn37xvRzU0pJY2Oj5ObmSnKy6f52jBl6Nzz0bvzQu+Exe++abma85ORk6dOnj39mrPT0dBquA2L9uTmdzpi9l1nRu5FB78YevRsZZu3dxP0TFgCABMBADwCAjZl2oHc4HDJv3jxxOBzxLsVS+Nzij59Bx/C5xR8/g44x++dmuoPxAABA5Jh2ix4AAISPgR4AABtjoAcAwMYY6AEAsDEGegAAbMy0A/3ixYulf//+0rlzZxk+fLh8/PHH8S7JNEpLS6WgoEDS0tIkKytLJkyYIDU1Ndo6x44dE7fbLT169JBu3brJpEmTxOPxxKnixELvto3eNTd6t22W7l1lQitXrlSpqanqpZdeUjt37lRTp05VGRkZyuPxxLs0UyguLlbLli1T1dXVaseOHeqaa65RLpdLHTp0yL/O9OnTVd++fVV5ebmqrKxUI0aMUCNHjoxj1YmB3g2M3jUvejcwK/euKQf6YcOGKbfb7c8tLS0qNzdXlZaWxrEq8/ruu++UiKjNmzcrpZRqaGhQKSkpavXq1f51du/erUREVVRUxKvMhEDvhobeNQ96NzRW6l3TfXXf3NwsVVVVUlRU5L8vOTlZioqKpKKiIo6VmZfX6xURkczMTBERqaqqkuPHj2uf4cCBA8XlcvEZRhG9Gzp61xzo3dBZqXdNN9AfPHhQWlpaJDs7W7s/Oztb6uvr41SVebW2tsqsWbNk1KhRMnjwYBERqa+vl9TUVMnIyNDW5TOMLno3NPSuedC7obFa75ruMrUIjdvtlurqatm6dWu8SwFCQu/CqqzWu6bbou/Zs6d06tTplCMVPR6P5OTkxKkqcyopKZF169bJxo0bpU+fPv77c3JypLm5WRoaGrT1+Qyji94NHr1rLvRu8KzYu6Yb6FNTUyU/P1/Ky8v997W2tkp5ebkUFhbGsTLzUEpJSUmJrFmzRjZs2CB5eXna4/n5+ZKSkqJ9hjU1NVJbW8tnGEX0bvvoXXOid9tn6d6N66GAbVi5cqVyOByqrKxM7dq1S02bNk1lZGSo+vr6eJdmCjNmzFBOp1Nt2rRJ7d+/378cOXLEv8706dOVy+VSGzZsUJWVlaqwsFAVFhbGserEQO8GRu+aF70bmJV715QDvVJKLVq0SLlcLpWamqqGDRumtm3bFu+STENETrssW7bMv87Ro0fVfffdp7p3767OOOMMNXHiRLV///74FZ1A6N220bvmRu+2zcq9y/XoAQCwMdPtowcAAJHDQA8AgI0x0AMAYGMM9AAA2BgDPQAANsZADwCAjTHQAwBgYwz0AADYGAM9AAA2xkAPAICNMdADAGBj/x80txMDcNY16gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core import latex_symbols\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "      super(NeuralNet, self).__init__()\n",
        "      self.l1 = nn.Linear(input_size, hidden_size)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = self.l1(x)\n",
        "      out = self.relu(out)\n",
        "      out = self.l2(out)\n",
        "      return out;\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "#Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      #original shape: [100, 1, 28*28] 2d array\n",
        "      # resized: [100, 784] one d array\n",
        "      images = images.reshape(-1, 28*28).to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      output = model(images)\n",
        "      loss = criterion(output, labels)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      if(i+1) % 100 == 0:\n",
        "        print(f'epoch [{epoch+1}/{num_epochs}], step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NXGtu3Ufj6o",
        "outputId": "f1c30558-b1c3-4044-dd1a-7801044b1ec9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/10], step [100/600], Loss: 2.2618\n",
            "epoch [1/10], step [200/600], Loss: 2.2612\n",
            "epoch [1/10], step [300/600], Loss: 2.2589\n",
            "epoch [1/10], step [400/600], Loss: 2.2253\n",
            "epoch [1/10], step [500/600], Loss: 2.1874\n",
            "epoch [1/10], step [600/600], Loss: 2.2033\n",
            "epoch [2/10], step [100/600], Loss: 2.1702\n",
            "epoch [2/10], step [200/600], Loss: 2.1527\n",
            "epoch [2/10], step [300/600], Loss: 2.1592\n",
            "epoch [2/10], step [400/600], Loss: 2.1205\n",
            "epoch [2/10], step [500/600], Loss: 2.1001\n",
            "epoch [2/10], step [600/600], Loss: 2.0922\n",
            "epoch [3/10], step [100/600], Loss: 2.0692\n",
            "epoch [3/10], step [200/600], Loss: 2.0316\n",
            "epoch [3/10], step [300/600], Loss: 2.0346\n",
            "epoch [3/10], step [400/600], Loss: 2.0245\n",
            "epoch [3/10], step [500/600], Loss: 1.9916\n",
            "epoch [3/10], step [600/600], Loss: 2.0195\n",
            "epoch [4/10], step [100/600], Loss: 1.9816\n",
            "epoch [4/10], step [200/600], Loss: 1.9521\n",
            "epoch [4/10], step [300/600], Loss: 1.9446\n",
            "epoch [4/10], step [400/600], Loss: 1.9128\n",
            "epoch [4/10], step [500/600], Loss: 1.8963\n",
            "epoch [4/10], step [600/600], Loss: 1.8351\n",
            "epoch [5/10], step [100/600], Loss: 1.8637\n",
            "epoch [5/10], step [200/600], Loss: 1.8442\n",
            "epoch [5/10], step [300/600], Loss: 1.7998\n",
            "epoch [5/10], step [400/600], Loss: 1.7989\n",
            "epoch [5/10], step [500/600], Loss: 1.8128\n",
            "epoch [5/10], step [600/600], Loss: 1.7142\n",
            "epoch [6/10], step [100/600], Loss: 1.8194\n",
            "epoch [6/10], step [200/600], Loss: 1.6826\n",
            "epoch [6/10], step [300/600], Loss: 1.7188\n",
            "epoch [6/10], step [400/600], Loss: 1.6380\n",
            "epoch [6/10], step [500/600], Loss: 1.6600\n",
            "epoch [6/10], step [600/600], Loss: 1.6461\n",
            "epoch [7/10], step [100/600], Loss: 1.5875\n",
            "epoch [7/10], step [200/600], Loss: 1.6097\n",
            "epoch [7/10], step [300/600], Loss: 1.4889\n",
            "epoch [7/10], step [400/600], Loss: 1.4740\n",
            "epoch [7/10], step [500/600], Loss: 1.5299\n",
            "epoch [7/10], step [600/600], Loss: 1.5587\n",
            "epoch [8/10], step [100/600], Loss: 1.4194\n",
            "epoch [8/10], step [200/600], Loss: 1.5196\n",
            "epoch [8/10], step [300/600], Loss: 1.4398\n",
            "epoch [8/10], step [400/600], Loss: 1.4273\n",
            "epoch [8/10], step [500/600], Loss: 1.4801\n",
            "epoch [8/10], step [600/600], Loss: 1.4413\n",
            "epoch [9/10], step [100/600], Loss: 1.3799\n",
            "epoch [9/10], step [200/600], Loss: 1.3291\n",
            "epoch [9/10], step [300/600], Loss: 1.1855\n",
            "epoch [9/10], step [400/600], Loss: 1.3197\n",
            "epoch [9/10], step [500/600], Loss: 1.3137\n",
            "epoch [9/10], step [600/600], Loss: 1.3320\n",
            "epoch [10/10], step [100/600], Loss: 1.2946\n",
            "epoch [10/10], step [200/600], Loss: 1.3227\n",
            "epoch [10/10], step [300/600], Loss: 1.2326\n",
            "epoch [10/10], step [400/600], Loss: 1.2372\n",
            "epoch [10/10], step [500/600], Loss: 1.2031\n",
            "epoch [10/10], step [600/600], Loss: 1.2747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = len(test_loader.dataset)\n",
        "\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    output = model(images)\n",
        "\n",
        "    _,predicted = torch.max(output, 1)\n",
        "    n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "  acc = n_correct / n_samples\n",
        "  print(f'Accuracy on {n_samples} test images: {100*acc}%' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7yyyU7TjkIP",
        "outputId": "74ef1866-9d4d-4f6d-a768-2460f076b545"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on 10000 test images: 79.56%\n"
          ]
        }
      ]
    }
  ]
}